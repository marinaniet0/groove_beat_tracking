{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Groove Beat Tracking - Marina Nieto",
      "provenance": [],
      "collapsed_sections": [
        "PFJfUWARVq1Q",
        "iwbQIo6fVzkv",
        "CHKoLRCyHyna",
        "gYy_vf_4AzNt",
        "REyjvMt1A2JA"
      ],
      "authorship_tag": "ABX9TyNYTugFIuYcdxv/LxRdZ+80",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marinaniet0/groove_beat_tracking/blob/main/Groove_Beat_Downbeat_Tracking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G64P-TahPLc5"
      },
      "source": [
        "# Beat and downbeat tracking\n",
        "\n",
        "In this notebook, two models are trained and evaluated on the task of beat and downbeat tracking using the Groove Midi Dataset. The data formatting, the models and the hyper parameters are taken (with some small modifications to fit the dataset used) from [[1]](#1).\n",
        "\n",
        "<a id=\"1\">[1]</a> \n",
        "Y. -C. Chuang and L. Su, \"Beat and Downbeat Tracking of Symbolic Music Data Using Deep Recurrent Neural Networks\", *2020 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)*, 2020, pp. 346-352. Implementation: https://github.com/chuang76/symbolic-beat-tracking/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFJfUWARVq1Q"
      },
      "source": [
        "## Model architecture\n",
        "\n",
        "The two models trained are a \"vanilla\" BLSTM and a BLSTM with an attention mechanism. In both cases we have a Recurrent Neural Network with 2 layers and\n",
        "25 units per layer. The models output the probability of a time step being a beat or not, and the probability of it being a down beat or not. The models are trained over 50 epochs, using the Binary Cross Entropy loss of beats and downbeats. To transform the probabilities, the outputs are thresholded (0.3 for the BLSTM and 0.2 for the BLSTM + attention). An overview of the architecture is shown below in images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4ZGshxCHnwc"
      },
      "source": [
        "### BLSTM\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1BKMz9rfHZhdABfL9Soo1X1Xy-ZIPvcoE)\n",
        "\n",
        "### BLSTM + Attention\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=11WpRqaU_20G6AP-C-cls-BpjSCOk3Vv0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwbQIo6fVzkv"
      },
      "source": [
        "## Dataset preprocessing\n",
        "\n",
        "The MIDI-only version of the [Groove MIDI Dataset](https://magenta.tensorflow.org/datasets/groove) is downloaded and processed here.  \n",
        "Since the dataset is already split in train, test and validation sets, I use the train subset for its intended purpose and the validation set to compute the evaluation later on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRXWEdYGWCLv",
        "outputId": "a827d69c-3544-4184-db5b-ff354984e4cb"
      },
      "source": [
        "# Installing pretty_midi - Necessary for the preprocessing\n",
        "%%time\n",
        "!pip install pretty_midi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pretty_midi\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/8e/63c6e39a7a64623a9cd6aec530070c70827f6f8f40deec938f323d7b1e15/pretty_midi-0.2.9.tar.gz (5.6MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6MB 4.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from pretty_midi) (1.19.5)\n",
            "Collecting mido>=1.1.16\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b5/6d/e18a5b59ff086e1cd61d7fbf943d86c5f593a4e68bfc60215ab74210b22b/mido-1.2.10-py2.py3-none-any.whl (51kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pretty_midi) (1.15.0)\n",
            "Building wheels for collected packages: pretty-midi\n",
            "  Building wheel for pretty-midi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretty-midi: filename=pretty_midi-0.2.9-cp37-none-any.whl size=5591954 sha256=e85c2072f5c7a5489813ad2653378b8c835a4ff16a5553515db3f7a497a60b84\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/a1/c6/b5697841db1112c6e5866d75a6b6bf1bef73b874782556ba66\n",
            "Successfully built pretty-midi\n",
            "Installing collected packages: mido, pretty-midi\n",
            "Successfully installed mido-1.2.10 pretty-midi-0.2.9\n",
            "CPU times: user 63.9 ms, sys: 18.4 ms, total: 82.2 ms\n",
            "Wall time: 6.17 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eglbe0GYYjGh"
      },
      "source": [
        "# Downloading and unzipping the Groove MIDI Dataset\n",
        "!wget https://storage.googleapis.com/magentadata/datasets/groove/groove-v1.0.0-midionly.zip\n",
        "!unzip /content/groove-v1.0.0-midionly.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2PkLyLIaLNz"
      },
      "source": [
        "# Imports\n",
        "import os\n",
        "import pandas as pd\n",
        "import pretty_midi\n",
        "import numpy as np\n",
        "from scipy.interpolate import interp1d\n",
        "import pickle\n",
        "import glob"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huoZ5YOkzXwk"
      },
      "source": [
        "current_dir = os.getcwd() + '/'\n",
        "groove_dir = current_dir + 'groove/'\n",
        "train_dir = current_dir + 'train/'\n",
        "validation_dir = current_dir + 'validation/'\n",
        "\n",
        "if not os.path.exists(train_dir):\n",
        "  os.makedirs(train_dir)\n",
        "\n",
        "if not os.path.exists(validation_dir):\n",
        "  os.makedirs(validation_dir)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "5bvZ6XrZaRPP",
        "outputId": "57f36b2b-13fc-4ee8-ba49-9b836d77d1b9"
      },
      "source": [
        "# Load dataframe and display Groove info examples\n",
        "groove_info = pd.read_csv(groove_dir + 'info.csv')\n",
        "groove_info.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>drummer</th>\n",
              "      <th>session</th>\n",
              "      <th>id</th>\n",
              "      <th>style</th>\n",
              "      <th>bpm</th>\n",
              "      <th>beat_type</th>\n",
              "      <th>time_signature</th>\n",
              "      <th>midi_filename</th>\n",
              "      <th>audio_filename</th>\n",
              "      <th>duration</th>\n",
              "      <th>split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>drummer1</td>\n",
              "      <td>drummer1/eval_session</td>\n",
              "      <td>drummer1/eval_session/1</td>\n",
              "      <td>funk/groove1</td>\n",
              "      <td>138</td>\n",
              "      <td>beat</td>\n",
              "      <td>4-4</td>\n",
              "      <td>drummer1/eval_session/1_funk-groove1_138_beat_...</td>\n",
              "      <td>drummer1/eval_session/1_funk-groove1_138_beat_...</td>\n",
              "      <td>27.872308</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>drummer1</td>\n",
              "      <td>drummer1/eval_session</td>\n",
              "      <td>drummer1/eval_session/10</td>\n",
              "      <td>soul/groove10</td>\n",
              "      <td>102</td>\n",
              "      <td>beat</td>\n",
              "      <td>4-4</td>\n",
              "      <td>drummer1/eval_session/10_soul-groove10_102_bea...</td>\n",
              "      <td>drummer1/eval_session/10_soul-groove10_102_bea...</td>\n",
              "      <td>37.691158</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>drummer1</td>\n",
              "      <td>drummer1/eval_session</td>\n",
              "      <td>drummer1/eval_session/2</td>\n",
              "      <td>funk/groove2</td>\n",
              "      <td>105</td>\n",
              "      <td>beat</td>\n",
              "      <td>4-4</td>\n",
              "      <td>drummer1/eval_session/2_funk-groove2_105_beat_...</td>\n",
              "      <td>drummer1/eval_session/2_funk-groove2_105_beat_...</td>\n",
              "      <td>36.351218</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>drummer1</td>\n",
              "      <td>drummer1/eval_session</td>\n",
              "      <td>drummer1/eval_session/3</td>\n",
              "      <td>soul/groove3</td>\n",
              "      <td>86</td>\n",
              "      <td>beat</td>\n",
              "      <td>4-4</td>\n",
              "      <td>drummer1/eval_session/3_soul-groove3_86_beat_4...</td>\n",
              "      <td>drummer1/eval_session/3_soul-groove3_86_beat_4...</td>\n",
              "      <td>44.716543</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>drummer1</td>\n",
              "      <td>drummer1/eval_session</td>\n",
              "      <td>drummer1/eval_session/4</td>\n",
              "      <td>soul/groove4</td>\n",
              "      <td>80</td>\n",
              "      <td>beat</td>\n",
              "      <td>4-4</td>\n",
              "      <td>drummer1/eval_session/4_soul-groove4_80_beat_4...</td>\n",
              "      <td>drummer1/eval_session/4_soul-groove4_80_beat_4...</td>\n",
              "      <td>47.987500</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    drummer                session  ...   duration split\n",
              "0  drummer1  drummer1/eval_session  ...  27.872308  test\n",
              "1  drummer1  drummer1/eval_session  ...  37.691158  test\n",
              "2  drummer1  drummer1/eval_session  ...  36.351218  test\n",
              "3  drummer1  drummer1/eval_session  ...  44.716543  test\n",
              "4  drummer1  drummer1/eval_session  ...  47.987500  test\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lybSAoEvbK3b"
      },
      "source": [
        "In order to save and load the processing and the models, I used Google Drive, but for reproduction's sake, I will do the processing in the current working directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmcSFGs1yC3l"
      },
      "source": [
        "# Each beat value is mapped to a grid of resolution 16 divisions per beat\n",
        "def find_nearest_to_grid(value):\n",
        "  grid = np.arange(17) / 16.0\n",
        "  idx = (np.abs(grid - value)).argmin()\n",
        "  return grid[idx]\n",
        "\n",
        "# Sync notes that are on the same start beat to the start time of the first of\n",
        "# those notes\n",
        "def align_notes_per_beat(dataframe):\n",
        "  for idx, row in dataframe.iterrows():\n",
        "    dataframe.loc[dataframe.index[dataframe['start_beat'] ==\\\n",
        "                  row['start_beat']],'start_time'] =\\\n",
        "                  dataframe.loc[dataframe.index[dataframe['start_beat'] ==\\\n",
        "                  row['start_beat']][0],'start_time']\n",
        "\n",
        "# With this function, CSV files with the same format as those from Chuang et al.\n",
        "# are created from the midi files\n",
        "def midi2csv(midi_file, bpm, time_signature, save_dir):\n",
        "\n",
        "  if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "\n",
        "  data = pretty_midi.PrettyMIDI(midi_file)\n",
        "  name = midi_file.split('/')[-1].split('.')[0]\n",
        "\n",
        "  time_signature_num = int(time_signature.split('-')[0])\n",
        "  time_signature_den = int(time_signature.split('-')[1])\n",
        "\n",
        "  beat_secs = (60/bpm) / (time_signature_den/4) # n beats in a second\n",
        "  downbeat_samples = beat_secs * time_signature_num\n",
        "\n",
        "  midi_list = []\n",
        "\n",
        "  for instrument in data.instruments:\n",
        "    for note in instrument.notes:\n",
        "      start = int(note.start * 44100)\n",
        "      end = int(note.end * 44100)\n",
        "      pitch = note.pitch\n",
        "      start_beat = note.start / beat_secs\n",
        "      start_beat_decimal_grid = find_nearest_to_grid(start_beat % 1)\n",
        "      start_beat_grid = float(str(start_beat).split('.')[0]) + start_beat_decimal_grid\n",
        "      midi_list.append([start, end, start_beat_grid, pitch])\n",
        "\n",
        "  midi_list = sorted(midi_list, key=lambda x: (x[0], x[3]))\n",
        "  df = pd.DataFrame(midi_list, columns=['start_time', 'end_time', 'start_beat', 'note'])\n",
        "  align_notes_per_beat(df)\n",
        "  new_path = save_dir + midi_file.split('.')[0].split('/')[-1]\n",
        "  new_filename = new_path +'.csv'\n",
        "  df.to_csv(new_filename)\n",
        "  return new_filename"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SV0qeZ53xqbK"
      },
      "source": [
        "# Create a list with the subsets of midi files\n",
        "train_file_list = []\n",
        "validation_file_list = []\n",
        "\n",
        "groove_info = pd.read_csv(groove_dir + 'info.csv')\n",
        "\n",
        "for i in np.arange(len(groove_info)):\n",
        "  if groove_info.iloc[i]['split'] == 'train':\n",
        "    train_file_list.append(groove_dir + groove_info.iloc[i]['midi_filename'])\n",
        "  else:\n",
        "    validation_file_list.append(groove_dir + groove_info.iloc[i]['midi_filename'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvdbCFLtzEWH",
        "outputId": "e5b82ad5-c062-47f9-c8b5-424dac70e505"
      },
      "source": [
        "%%time\n",
        "spinner=['⠛','⠗','⠕','⠕','⠧','⠑']\n",
        "count = 0\n",
        "\n",
        "train_csv_list = []\n",
        "validation_csv_list = []\n",
        "\n",
        "train_csv_dir = train_dir + 'csv/'\n",
        "validation_csv_dir = validation_dir + 'csv/'\n",
        "\n",
        "if not os.path.exists(train_csv_dir):\n",
        "  os.makedirs(train_csv_dir)\n",
        "if not os.path.exists(validation_csv_dir):\n",
        "  os.makedirs(validation_csv_dir)\n",
        "\n",
        "i = 0\n",
        "for file in train_file_list:\n",
        "  time_signature = file.split('.')[0].split('_')[-1]\n",
        "  bpm = int(file.split('_')[-3])\n",
        "  print(\"\\r\" + spinner[count%6] + \"  \" + str(i) + \"/\" +\\\n",
        "        str(len(train_file_list)), file, time_signature, str(bpm), sep=\" | \",\\\n",
        "        end=\"\")\n",
        "  train_csv_list.append(midi2csv(file, bpm, time_signature, train_csv_dir))\n",
        "  count += 1\n",
        "  i += 1\n",
        "\n",
        "i = 0\n",
        "for file in validation_file_list:\n",
        "  time_signature = file.split('.')[0].split('_')[-1]\n",
        "  bpm = int(file.split('_')[-3])\n",
        "  print(\"\\r\" + spinner[count%6] + \"  \" + str(i) + \"/\" +\\\n",
        "        str(len(validation_file_list)), file, time_signature, str(bpm),\\\n",
        "        sep=\" | \", end=\"\")\n",
        "  validation_csv_list.append(midi2csv(file, bpm, time_signature,\\\n",
        "                                      validation_csv_dir))\n",
        "  count += 1\n",
        "  i += 1"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "⠕  252/253 | /content/groove/drummer2/session2/2_rock_130_beat_4-4.mid | 4-4 | 130CPU times: user 9min 23s, sys: 25.8 s, total: 9min 49s\n",
            "Wall time: 9min 15s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqu_t24M0joC"
      },
      "source": [
        "Now that we have the csv files similar to the ones used in Chuang et al., we calculate the X, Yb and Yd that will serve as input and output to the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYLs7XmZ0fFp"
      },
      "source": [
        "midi_notes_groove = [22,26,36,37,38,40,42,43,44,45,46,47,48,49,50,51,52,53,55,\n",
        "                      57,58,59]\n",
        "def preprocess_data(dir_csv, dir_npz, csv_list, window_sz, large_save_dir,\\\n",
        "                    save_name, join=True):\n",
        "  # No need to calculate onsets, offsets, etc. for notes not used in the dataset\n",
        "  # and this is the reduced mapping of the Groove Dataset\n",
        "  \n",
        "  n_notes = len(midi_notes_groove)\n",
        "  print(str(len(csv_list)) + \" files!\")\n",
        "\n",
        "  # Template arrays for the onsets and durations\n",
        "  N = []\n",
        "  for i in midi_notes_groove:\n",
        "    N.append(str(i) + '/onset')\n",
        "  for i in midi_notes_groove:\n",
        "    N.append(str(i) + '/dur')\n",
        "\n",
        "  # Iterate through csv files\n",
        "  for file_idx in range(len(csv_list)):\n",
        "    data = pd.read_csv(csv_list[file_idx])\n",
        "    name = csv_list[file_idx].split('/')[-1]\n",
        "\n",
        "    print(\"\\r\" + \"  \" + str(file_idx+1) + '/' +\\\n",
        "          str(len(csv_list)), name, end=\"\")\n",
        "\n",
        "    # Create array of resolution 100 frames per second up to maximum end_time\n",
        "    length = int(data['end_time'].max() / 44100)\n",
        "    length = length if length > 0 else 1\n",
        "    z = pd.DataFrame(np.zeros((length * 100, 1)))\n",
        "\n",
        "    # Initialize IOI, beat and downbeat columns\n",
        "    new = pd.DataFrame()\n",
        "    for i in range(len(N)):\n",
        "      new[N[i]] = z[0]\n",
        "    new['IOI'], new['beat'], new['downbeat'] = z[0], z[0], z[0]\n",
        "\n",
        "    # Get time signature from file name\n",
        "    time_signature = name.split('_')[-1].split('.')[0]\n",
        "    time_signature_den = int(time_signature.split('-')[1])\n",
        "    # to account for 6/8 time signature, divide by denom/4\n",
        "    m = int(time_signature.split('-')[0]) / (time_signature_den/4)\n",
        "\n",
        "    # Get last beat\n",
        "    B = int(data['start_beat'].max())\n",
        "\n",
        "    # These are the beats that should be detected - reference list\n",
        "    ref_list = np.arange(B+1)\n",
        "\n",
        "\n",
        "    # Creating x,y and interpolation lists\n",
        "    x_list, y_list = [], []\n",
        "    x_interp = data['start_beat'].to_numpy()\n",
        "    y_interp = np.around(data['start_time'] / 44100 * 100, 0).to_numpy()\n",
        "\n",
        "    # Appending integer existing beats to x and y lists\n",
        "    for i in range(len(data)):\n",
        "      if data['start_beat'][i].is_integer():\n",
        "        x_list.append(data['start_beat'][i])\n",
        "        y_list.append(np.around(data['start_time'][i] / 44100 * 100, 0))\n",
        "\n",
        "    # Creating list of 'missing' beats\n",
        "    lost_list = []\n",
        "    for i in range(len(ref_list)):\n",
        "      if ref_list[i] not in y_list and ref_list[i] >= data['start_beat'].min():\n",
        "        lost_list.append(ref_list[i])\n",
        "\n",
        "    # Interpolation to create array of insert beats & downbeats\n",
        "    f = interp1d(y_interp, x_interp, kind='linear', fill_value='extrapolate')\n",
        "    insert_beat = []\n",
        "    for i in range(len(lost_list)):\n",
        "      idx = lost_list[i]\n",
        "      t = np.round(f(idx), 0)\n",
        "      if idx % m == 0:\n",
        "        d = 1\n",
        "      else:\n",
        "        d = 0 \n",
        "      insert_beat.append([t, 1, d])\n",
        "\n",
        "    # Onset and duration calculations\n",
        "    onset_arr = []                     \n",
        "    for i in range(len(data)):\n",
        "      pitch = data['note'][i]\n",
        "      onset = int(np.round(data['start_time'][i] / 44100 * 100, 0))\n",
        "      offset = int(np.round(data['end_time'][i] / 44100 * 100, 0))\n",
        "      beat = data['start_beat'][i] \n",
        "      onset_arr.append(onset)\n",
        "\n",
        "      # Assign onsets and durations\n",
        "      new[str(pitch) + '/onset'][onset] = 1\n",
        "      new[str(pitch) + '/dur'][onset:offset+1] = 1 \n",
        "      \n",
        "      # Add beat and downbeat if it corresponds\n",
        "      if beat.is_integer(): # beat\n",
        "        new['beat'][onset] = 1 \n",
        "        if beat % int(m) == 0:\n",
        "          new['downbeat'][onset] = 1\n",
        "\n",
        "    onset_arr = np.array(onset_arr)\n",
        "    onset_arr = np.unique(onset_arr)\n",
        "    onset_list = onset_arr.tolist()\n",
        "\n",
        "    # IOI \n",
        "    for i in range(len(onset_list)):\n",
        "      if i == 0:\n",
        "        num = 0.0\n",
        "        new['IOI'][onset_list[i]] = num\n",
        "      else:\n",
        "        num = np.round(float(onset_list[i] - onset_list[i-1]) * 0.01, 2)\n",
        "        new['IOI'][onset_list[i]] = num\n",
        "\n",
        "    # Add missing beats and downbeats\n",
        "    for i in range(len(insert_beat)):\n",
        "      new['beat'][insert_beat[i][0]] = insert_beat[i][1]\n",
        "      new['downbeat'][insert_beat[i][0]] = insert_beat[i][2]\n",
        "\n",
        "    # Save to temporary csv\n",
        "    path = dir_csv + name\n",
        "    new.to_csv(path)\n",
        "\n",
        "    # =========================================================================\n",
        "\n",
        "    # Load Yb with beat column, Yd with downbeat column, and X with the\n",
        "    # remaining info\n",
        "    X = pd.read_csv(path)\n",
        "    name = path.split('/')[-1].split('.')[0]\n",
        "    Yb, Yd = pd.DataFrame(X, columns=['beat']).to_numpy(), pd.DataFrame(X,\\\n",
        "                                            columns=['downbeat']).to_numpy()\n",
        "    X = X.drop(['beat', 'downbeat', 'Unnamed: 0'], axis=1).to_numpy()   \n",
        "\n",
        "    # setting \n",
        "    rows = len(X)\n",
        "    z = np.zeros((rows, 1))\n",
        "    z = pd.DataFrame(z)\n",
        "\n",
        "    # Calculate spectral flux \n",
        "    X_sf = np.zeros((len(X), len(midi_notes_groove)))\n",
        "    for i in range(len(X)):\n",
        "      if i != len(X) - 1:\n",
        "        X_sf[i] = np.maximum(X[i+1][:len(midi_notes_groove)] \\\n",
        "                             - X[i][:len(midi_notes_groove)], 0)\n",
        "\n",
        "    X_sf = np.sum(X_sf, axis=1)\n",
        "    X_sf = X_sf[:, np.newaxis]\n",
        "    X = np.concatenate((X, X_sf), axis=1)\n",
        "\n",
        "    # Split the data in overlapping fragments of window_sz size\n",
        "    num_frag = int(len(X) / window_sz)\n",
        "    if num_frag * window_sz + window_sz > len(X):\n",
        "      num_frag = num_frag - 1\n",
        "\n",
        "    idx_list = []\n",
        "    for i in range(num_frag):\n",
        "      start_idx = window_sz * i\n",
        "      end_idx = start_idx + (window_sz * 2)\n",
        "      idx = int((start_idx + end_idx) / 2)\n",
        "      idx_list.append(idx)\n",
        "\n",
        "    # Transform to frame-level \n",
        "    X_data = []\n",
        "    for i in idx_list:    \n",
        "      X_data.append(X[i-window_sz:i+window_sz])\n",
        "\n",
        "    Yb_data, Yd_data = [], []\n",
        "    for i in idx_list:    \n",
        "      Yb_data.append(Yb[i-window_sz:i+window_sz])\n",
        "      Yd_data.append(Yd[i-window_sz:i+window_sz])\n",
        "    Yb_data, Yd_data = np.squeeze(Yb_data, axis=2), np.squeeze(Yd_data, axis=2)\n",
        "\n",
        "    # Save to temporary individual npz files\n",
        "    with open(dir_npz + name + '.npz', 'wb') as f:\n",
        "      pickle.dump([X_data, Yb_data, Yd_data], f)\n",
        "\n",
        "\n",
        "  if(join):\n",
        "    print('\\n----------------------------')\n",
        "    print('Joining files...')\n",
        "\n",
        "    data_list = np.sort(glob.glob(dir_npz + '*.npz')).tolist()\n",
        "    X_data, Yb_data, Yd_data, Yt_data = [], [], [], []\n",
        "\n",
        "    for idx in range(len(data_list)):\n",
        "      with open(data_list[idx], 'rb') as f:\n",
        "        data = pickle.load(f)\n",
        "        X_data.append(data[0])\n",
        "        Yb_data.append(data[1])\n",
        "        Yd_data.append(data[2])\n",
        "\n",
        "    X = np.concatenate(X_data)\n",
        "    Yb = np.concatenate(Yb_data)\n",
        "    Yd = np.concatenate(Yd_data)\n",
        "\n",
        "    with open(large_save_dir + save_name, 'wb') as f:\n",
        "      pickle.dump([X, Yb, Yd], f, protocol=4)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lRt2f6N41kB",
        "outputId": "3022b3fc-8e92-444d-e962-50e3eaaa0e32"
      },
      "source": [
        "# Process training data\n",
        "print('Training data...')\n",
        "dir_csv_training = train_dir + 'tmp/csv/'\n",
        "dir_npz_training = train_dir + 'tmp/npz/'\n",
        "if not os.path.exists(dir_csv_training):\n",
        "    os.makedirs(dir_csv_training)\n",
        "if not os.path.exists(dir_npz_training):\n",
        "    os.makedirs(dir_npz_training)\n",
        "preprocess_data(dir_csv=dir_csv_training, dir_npz=dir_npz_training,\\\n",
        "                csv_list=train_csv_list, window_sz=50,\\\n",
        "                large_save_dir=train_dir, save_name='train_data.npz')\n",
        "\n",
        "print('\\n\\nValidation data...')\n",
        "dir_csv_validation = validation_dir + 'tmp/csv/'\n",
        "dir_npz_validation = validation_dir + 'tmp/npz/'\n",
        "if not os.path.exists(dir_csv_validation):\n",
        "    os.makedirs(dir_csv_validation)\n",
        "if not os.path.exists(dir_npz_validation):\n",
        "    os.makedirs(dir_npz_validation)\n",
        "preprocess_data(dir_csv=dir_csv_validation, dir_npz=dir_npz_validation,\\\n",
        "                csv_list=validation_csv_list, window_sz=50,\\\n",
        "                large_save_dir=validation_dir, save_name='validation_data.npz',\\\n",
        "                join=False)\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data...\n",
            "897 files!\n",
            "  13/897 110_funk_95_fill_4-4.csv"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/interpolate/interpolate.py:609: RuntimeWarning: invalid value encountered in true_divide\n",
            "  slope = (y_hi - y_lo) / (x_hi - x_lo)[:, None]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  226/897 11_country_114_fill_4-4.csv"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/interpolate/interpolate.py:609: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  slope = (y_hi - y_lo) / (x_hi - x_lo)[:, None]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  897/897 15_rock_130_beat_4-4.csv\n",
            "----------------------------\n",
            "Joining files...\n",
            "\n",
            "\n",
            "Validation data...\n",
            "253 files!\n",
            "  253/253 2_rock_130_beat_4-4.csv"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSTZ9Ne9rhl8"
      },
      "source": [
        "#@markdown Download processed files for later use\n",
        "from google.colab import files\n",
        "import os\n",
        "if not os.path.exists(current_dir + 'train_data.zip'):\n",
        "  print(\"Zipping training file...\")\n",
        "  !zip -j -r /content/train_data.zip /content/train/train_data.npz\n",
        "files.download(current_dir + 'train_data.zip')\n",
        "if not os.path.exists(current_dir + 'validation_data.zip'):\n",
        "  print(\"Zipping validation files folder...\")\n",
        "  !zip -j -r /content/validation_data.zip /content/validation/tmp/npz\n",
        "files.download(current_dir + 'validation_data.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5iBwHnaAjCQ"
      },
      "source": [
        "## Training\n",
        "\n",
        "Now that we have the data processed and saved, we proceed to the training of the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHKoLRCyHyna"
      },
      "source": [
        "### Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5TvzSM3v0kT",
        "outputId": "98b442c2-92ef-446b-a502-f53c80693fe9"
      },
      "source": [
        "#@markdown ### Loading preprocessed data\n",
        "#@markdown If the preprocessing step was skipped, the data can be loaded from\n",
        "#@markdown the GitHub repo, \n",
        "import os\n",
        "!wget https://github.com/marinaniet0/groove_beat_tracking/blob/main/train_data.zip?raw=true -O train_data.zip\n",
        "if not os.path.exists(os.getcwd() + '/train/'):\n",
        "  os.makedirs(os.getcwd() + '/train/')\n",
        "!unzip -d /content/train/ /content/train_data.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-28 21:36:49--  https://github.com/marinaniet0/groove_beat_tracking/blob/main/train_data.zip?raw=true\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/marinaniet0/groove_beat_tracking/raw/main/train_data.zip [following]\n",
            "--2021-05-28 21:36:49--  https://github.com/marinaniet0/groove_beat_tracking/raw/main/train_data.zip\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/marinaniet0/groove_beat_tracking/main/train_data.zip [following]\n",
            "--2021-05-28 21:36:50--  https://raw.githubusercontent.com/marinaniet0/groove_beat_tracking/main/train_data.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17843032 (17M) [application/zip]\n",
            "Saving to: ‘train_data.zip’\n",
            "\n",
            "train_data.zip      100%[===================>]  17.02M  61.4MB/s    in 0.3s    \n",
            "\n",
            "2021-05-28 21:36:50 (61.4 MB/s) - ‘train_data.zip’ saved [17843032/17843032]\n",
            "\n",
            "Archive:  /content/train_data.zip\n",
            "  inflating: /content/train/train_data.npz  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "soCnQZKv0R8r",
        "outputId": "91f54a89-9ccb-4e2f-9669-d1fe9c02a423"
      },
      "source": [
        "# Mount Google Drive to save and load models - in case runtime disconnects!\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5yRX9JQz9D_"
      },
      "source": [
        "# In case we're starting from training directly, define dirs\n",
        "current_dir = os.getcwd() + '/'\n",
        "train_dir = current_dir + 'train/'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDIJl5S70L1b"
      },
      "source": [
        "drive_save_dir = current_dir + 'drive/MyDrive/marinanieto_mir/models/'\n",
        "if not os.path.exists(drive_save_dir):\n",
        "  os.makedirs(drive_save_dir)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYy_vf_4AzNt"
      },
      "source": [
        "### BLSTM training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxKncBY-ECzO"
      },
      "source": [
        "# Imports & model parameters\n",
        "import os\n",
        "import glob \n",
        "import numpy as np\n",
        "import pickle\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as func\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "torch.manual_seed(1)\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Same chunking/windowing size as in the preprocessing\n",
        "sz = 50\n",
        "\n",
        "# Sequences are 2 * the window size\n",
        "seq_len = sz * 2 \n",
        "\n",
        "# 46 is the input dim -> 22 notes onsets + 22 notes durations + IOI + SF\n",
        "input_dim = 46\n",
        "\n",
        "# 25 is the hidden dim -> 25 units per layer\n",
        "hidden_dim = 25\n",
        "\n",
        "# beat & down beat dim -> 2 * seq_len since outputs are seq_len x probab of beat,\n",
        "# seq_len x probab of not a beat, same for downbeat  \n",
        "beat_dim, downbeat_dim = seq_len * 2, seq_len * 2      \n",
        "\n",
        "lr, epochs, batch_sz, n_weights, gamma = 0.01, 50, 8, 5, 0.1\n",
        "\n",
        "model_name = 'blstm'\n",
        "training_file = train_dir + 'train_data.npz'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezmzUKfiA11a",
        "outputId": "f45656c3-01a2-4759-d7ef-11e0f0326d6f"
      },
      "source": [
        "# Class to load data to torch tensors\n",
        "class custom_dataset(Dataset):\n",
        "    def __init__(self, x, yb, yd):\n",
        "        self.x = x \n",
        "        self.yb, self.yd = yb, yd\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.FloatTensor(self.x[idx]), torch.FloatTensor(self.yb[idx]), torch.FloatTensor(self.yd[idx])\n",
        "\n",
        "# BLSTM model class\n",
        "class Model(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        super(Model, self).__init__()\n",
        "\n",
        "        # setting \n",
        "        self.flag = True\n",
        "        self.layer_sz = 2\n",
        "        self.bi_num = 2\n",
        "\n",
        "        # layer \n",
        "        self.norm = nn.LayerNorm([seq_len, input_dim])\n",
        "        self.rnn = nn.LSTM(input_dim, hidden_dim, batch_first=True, bidirectional=self.flag, num_layers=self.layer_sz)  \n",
        "        for name, param in self.rnn.named_parameters():                   # initialization\n",
        "            if 'bias' in name:\n",
        "                nn.init.uniform_(param, a=-0.1, b=0.1)\n",
        "            elif 'weight' in name:\n",
        "                nn.init.uniform_(param, a=-0.1, b=0.1)\n",
        "\n",
        "        self.beat = nn.ModuleList([nn.Linear(hidden_dim * self.bi_num, 1), \\\n",
        "                                   nn.Linear(hidden_dim * self.bi_num, 1)])         \n",
        "        self.act = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, raw):     \n",
        "        x = self.norm(raw)\n",
        "        out, (hn, cn) = self.rnn(x)\n",
        "        b, d = self.beat[0](out), self.beat[1](out)\n",
        "        b, d = self.act(b), self.act(d)\n",
        "        b, d = b.squeeze(-1), d.squeeze(-1)\n",
        "        return b, d, out    \n",
        "\n",
        "# Training function\n",
        "def main():\n",
        "\n",
        "    print('Loading dataset...')\n",
        "    with open(training_file, 'rb') as f:\n",
        "        data = pickle.load(f)\n",
        "    X_data, Yb_data, Yd_data = data[0], data[1], data[2]\n",
        "    dataset = custom_dataset(X_data, Yb_data, Yd_data)\n",
        "    train_loader = DataLoader(dataset, batch_size=batch_sz, drop_last=True)\n",
        "    print('Dataset loaded.')\n",
        "\n",
        "    del dataset\n",
        "    del X_data, Yb_data, Yd_data\n",
        "\n",
        "    model = Model(input_dim, hidden_dim)\n",
        "    model = model.to(device)\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=gamma)           \n",
        "    beat_loss = nn.BCELoss()\n",
        "\n",
        "    train_arr, test_arr = [], []\n",
        "\n",
        "    current_epoch = 0\n",
        "\n",
        "    # load latest checkpoint in drive_save_dir\n",
        "    if os.path.exists(drive_save_dir):\n",
        "      latest_ckpt = -1\n",
        "      latest_file = ''\n",
        "      for root, dirs, files in os.walk(drive_save_dir, topdown=False):\n",
        "        for name in files:\n",
        "          if name.startswith(model_name) and int(name.split('.')[0].split('_')[-1])\\\n",
        "           > latest_ckpt:\n",
        "              latest_ckpt = int(name.split('.')[0].split('_')[-1])\n",
        "              latest_file = os.path.join(root, name)\n",
        "\n",
        "      if latest_ckpt > -1 and len(latest_file) > 0:\n",
        "          ckpt = torch.load(latest_file)\n",
        "          model.load_state_dict(ckpt['model_state_dict'])\n",
        "          optimizer.load_state_dict(ckpt['optimizer_state_dict'])\n",
        "          current_epoch = latest_ckpt + 1\n",
        "          print('loaded!')\n",
        "\n",
        "    for epoch in range(current_epoch, epochs):\n",
        "\n",
        "        print('\\n[info] epoch %d' %(epoch), end='\\t')\n",
        "        epoch = \"%02d\" %(epoch)\n",
        "\n",
        "        lr_data = optimizer.param_groups[0]['lr']\n",
        "\n",
        "        model.train()                             \n",
        "        bl_loss, dl_loss = 0, 0      \n",
        "        for idx, (x, yb, yd) in enumerate(train_loader):\n",
        "\n",
        "            x, yb, yd = x.to(device), yb.to(device), yd.to(device)\n",
        "            b, d, out = model.forward(x)\n",
        "            bl, dl = beat_loss(b, yb), beat_loss(d, yd)\n",
        "            bl_loss += bl.item()                \n",
        "            dl_loss += dl.item()\n",
        "            train_loss = bl + dl * n_weights\n",
        "\n",
        "            optimizer.zero_grad()                # update \n",
        "            train_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        print('train loss = %.4f | beat loss = %.4f | downbeat loss = %.4f' % ((bl_loss + dl_loss) / idx, bl_loss / idx, dl_loss / idx))\n",
        "        train_arr.append([epoch, np.round(bl_loss / idx, 4), np.round(dl_loss / idx, 4)])\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        save_name = drive_save_dir + model_name + '_' + str(epoch) +'.pkl'\n",
        "        torch.save({\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                }, save_name)\n",
        "\n",
        "# Run main() :)\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n",
            "Dataset loaded.\n",
            "loaded!\n",
            "\n",
            "[info] epoch 49\ttrain loss = 0.0322 | beat loss = 0.0238 | downbeat loss = 0.0084\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REyjvMt1A2JA"
      },
      "source": [
        "### BLSTM + Attention training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZVdwBzhH-jF"
      },
      "source": [
        "# Imports & model parameters\n",
        "import os\n",
        "import glob \n",
        "import numpy as np\n",
        "import pickle\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as func\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "torch.manual_seed(1)\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Same chunking/windowing size as in the preprocessing\n",
        "sz = 50\n",
        "\n",
        "# Sequences are 2 * the window size\n",
        "seq_len = sz * 2 \n",
        "\n",
        "# 46 is the input dim -> 22 notes onsets + 22 notes durations + IOI + SF\n",
        "input_dim = 46\n",
        "\n",
        "# 25 is the hidden dim -> 25 units per layer\n",
        "hidden_dim = 25\n",
        "\n",
        "# beat & down beat dim -> 2 * seq_len since outputs are seq_len x probab of beat,\n",
        "# seq_len x probab of not a beat, same for downbeat  \n",
        "beat_dim, downbeat_dim = seq_len * 2, seq_len * 2      \n",
        "\n",
        "lr, epochs, batch_sz, n_weights, gamma = 0.01, 50, 8, 5, 0.1\n",
        "\n",
        "model_name = 'attn'\n",
        "training_file = train_dir + 'train_data.npz'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxRYNUrWA4vo",
        "outputId": "6e1f68b2-086a-4ad5-bd4b-ebd6f072d545"
      },
      "source": [
        "# Load data to tensor function\n",
        "class custom_dataset(Dataset):\n",
        "    def __init__(self, x, yb, yd):\n",
        "        self.x = x \n",
        "        self.yb, self.yd = yb, yd\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.FloatTensor(self.x[idx]), torch.FloatTensor(self.yb[idx]), torch.FloatTensor(self.yd[idx])\n",
        "\n",
        "# Attention mechanism definition\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, dimensions, attention_type='general'):\n",
        "        super(Attention, self).__init__()\n",
        "\n",
        "        if attention_type not in ['dot', 'general']:\n",
        "            raise ValueError('Invalid attention type selected.')\n",
        "\n",
        "        self.attention_type = attention_type\n",
        "        if self.attention_type == 'general':\n",
        "            self.linear_in = nn.Linear(dimensions, dimensions, bias=False)\n",
        "\n",
        "        self.linear_out = nn.Linear(dimensions * 2, dimensions, bias=False)\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, query, context):\n",
        "\n",
        "        batch_size, output_len, dimensions = query.size()\n",
        "        query_len = context.size(1)\n",
        "\n",
        "        if self.attention_type == \"general\":\n",
        "            query = query.reshape(batch_size * output_len, dimensions)\n",
        "            query = self.linear_in(query)\n",
        "            query = query.reshape(batch_size, output_len, dimensions)\n",
        "\n",
        "        # Computing attention scores\n",
        "        attention_scores = torch.bmm(query, context.transpose(1, 2).contiguous())\n",
        "        attention_scores = attention_scores.view(batch_size * output_len, query_len)\n",
        "        attention_weights = self.softmax(attention_scores)\n",
        "        attention_weights = attention_weights.view(batch_size, output_len, query_len)\n",
        "\n",
        "        mix = torch.bmm(attention_weights, context)\n",
        "        combined = torch.cat((mix, query), dim=2)\n",
        "        combined = combined.view(batch_size * output_len, 2 * dimensions)\n",
        "\n",
        "        # Pass through linear layer & hyperbolic tangent\n",
        "        output = self.linear_out(combined).view(batch_size, output_len, dimensions)\n",
        "        output = self.tanh(output)\n",
        "\n",
        "        return output, attention_weights\n",
        "\n",
        "# BLSTM + Attention model class\n",
        "class Model(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_dim, hidden_dim, beat_dim, downbeat_dim):\n",
        "        super(Model, self).__init__()\n",
        "\n",
        "        # setting \n",
        "        self.flag = True\n",
        "        self.layer_sz = 2\n",
        "\n",
        "        # layer \n",
        "        self.norm = nn.LayerNorm([seq_len, input_dim])\n",
        "        self.rnn = nn.LSTM(input_dim, hidden_dim, batch_first=True, bidirectional=self.flag, num_layers=self.layer_sz)  \n",
        "        for name, param in self.rnn.named_parameters():                   # initialization\n",
        "            if 'bias' in name:\n",
        "                nn.init.uniform_(param, a=-0.1, b=0.1)\n",
        "            elif 'weight' in name:\n",
        "                nn.init.uniform_(param, a=-0.1, b=0.1)\n",
        "\n",
        "        self.beat = nn.ModuleList([nn.Linear(hidden_dim, 1), \\\n",
        "                                   nn.Linear(hidden_dim, 1)])          \n",
        "\n",
        "        self.attn = Attention(hidden_dim)\n",
        "        self.act = nn.Sigmoid()\n",
        "    \n",
        "    def forward(self, raw):      \n",
        "\n",
        "        x = self.norm(raw)\n",
        "        out, (hn, cn) = self.rnn(x) \n",
        "        out_tmp = torch.chunk(out, 2, -1)\n",
        "        out_tmp = out_tmp[0] + out_tmp[1] \n",
        "        hn = hn.permute(1, 0, 2)\n",
        "        attn_out, weights = self.attn(out_tmp, hn)     # (8, 1201, 25)\n",
        "\n",
        "        # beat \n",
        "        b1, d1 = self.beat[0](attn_out), self.beat[1](attn_out)                   # (8, 1201, 1)\n",
        "        b, d = self.act(b1), self.act(d1)\n",
        "        b, d = b.squeeze(-1), d.squeeze(-1)                   # (8, 1201)\n",
        "\n",
        "        return b, d \n",
        "\n",
        "def main():\n",
        "    print('Loading dataset...')\n",
        "    with open(training_file, 'rb') as f:\n",
        "        data = pickle.load(f)\n",
        "    X_data, Yb_data, Yd_data = data[0], data[1], data[2]\n",
        "    dataset = custom_dataset(X_data, Yb_data, Yd_data)\n",
        "    train_loader = DataLoader(dataset, batch_size=batch_sz, drop_last=True)\n",
        "    print('Dataset loaded.')\n",
        "\n",
        "    del dataset\n",
        "    del X_data, Yb_data, Yd_data\n",
        "\n",
        "    # model, optim, loss \n",
        "    model = Model(input_dim, hidden_dim, beat_dim, downbeat_dim)\n",
        "    model = model.to(device)\n",
        "\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=gamma)           \n",
        "    beat_loss = nn.BCELoss()\n",
        "\n",
        "    train_arr, test_arr, lr_arr = [], [], []\n",
        "\n",
        "    current_epoch = 0\n",
        "\n",
        "    if os.path.exists(drive_save_dir):\n",
        "      latest_ckpt = -1\n",
        "      latest_file = ''\n",
        "      for root, dirs, files in os.walk(drive_save_dir, topdown=False):\n",
        "        for name in files:\n",
        "          if name.startswith(model_name) and int(name.split('.')[0].split('_')[-1])\\\n",
        "           > latest_ckpt:\n",
        "              latest_ckpt = int(name.split('.')[0].split('_')[-1])\n",
        "              latest_file = os.path.join(root, name)\n",
        "\n",
        "      if latest_ckpt > -1 and len(latest_file) > 0:\n",
        "          ckpt = torch.load(latest_file)\n",
        "          model.load_state_dict(ckpt['model_state_dict'])\n",
        "          optimizer.load_state_dict(ckpt['optimizer_state_dict'])\n",
        "          current_epoch = latest_ckpt + 1\n",
        "          print('Model loaded')\n",
        "\n",
        "    for epoch in range(current_epoch, epochs):\n",
        "\n",
        "        lr_data = optimizer.param_groups[0]['lr']\n",
        "        # print('lr_data =', lr_data)\n",
        "\n",
        "        print('\\n[info] epoch %d' %(epoch), end='\\t')\n",
        "\n",
        "        model.train()                               \n",
        "        bl_loss, dl_loss = 0, 0    \n",
        "\n",
        "        for idx, (x, yb, yd) in enumerate(train_loader):\n",
        "\n",
        "            x, yb, yd = x.to(device), yb.to(device), yd.to(device)\n",
        "            b, d = model.forward(x)\n",
        "\n",
        "            bl, dl = beat_loss(b, yb), beat_loss(d, yd)\n",
        "            bl_loss += bl.item()                \n",
        "            dl_loss += dl.item()\n",
        "            train_loss = bl + dl * n_weights\n",
        "\n",
        "            optimizer.zero_grad()                # update \n",
        "            train_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        print('train loss = %.4f | beat loss = %.4f | downbeat loss = %.4f' % ((bl_loss + dl_loss) / idx, bl_loss / idx, dl_loss / idx))\n",
        "        train_arr.append([epoch, np.round(bl_loss / idx, 4), np.round(dl_loss / idx, 4)])\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        save_name = drive_save_dir + model_name + '_' + str(epoch) +'.pkl'\n",
        "        torch.save({\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                }, save_name)   \n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n",
            "Dataset loaded.\n",
            "Model loaded\n",
            "\n",
            "[info] epoch 46\ttrain loss = 0.0324 | beat loss = 0.0240 | downbeat loss = 0.0084\n",
            "\n",
            "[info] epoch 47\ttrain loss = 0.0324 | beat loss = 0.0240 | downbeat loss = 0.0084\n",
            "\n",
            "[info] epoch 48\ttrain loss = 0.0324 | beat loss = 0.0240 | downbeat loss = 0.0084\n",
            "\n",
            "[info] epoch 49\ttrain loss = 0.0324 | beat loss = 0.0240 | downbeat loss = 0.0084\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0a_TmgHkA5op"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyD-BS0iJ8ze"
      },
      "source": [
        "### Reference beats for evaluation\n",
        "\n",
        "Downloading the validation preprocessed data in order to evaluate the models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHDfklpXDo1d"
      },
      "source": [
        "#@markdown ### Loading preprocessed data\n",
        "#@markdown If the preprocessing step was skipped, the validation data can be\n",
        "#@markdown loaded from the GitHub repo.\n",
        "import os\n",
        "!wget https://github.com/marinaniet0/groove_beat_tracking/blob/main/validation_data.zip?raw=true -O validation_data.zip\n",
        "if not os.path.exists(os.getcwd() + '/eval/npz/'):\n",
        "  os.makedirs(os.getcwd() + '/eval/npz/')\n",
        "!unzip -d /content/eval/npz/ /content/validation_data.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mx8dn1wDeu5"
      },
      "source": [
        "Once downloaded, the data is processed to match the output format (txt file with\n",
        "beat positions in seconds)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQJrT5aTKXiy",
        "outputId": "3c0052e4-4bdd-4734-cfab-36c0277d4e61"
      },
      "source": [
        "import os\n",
        "import glob \n",
        "import numpy as np\n",
        "import pickle \n",
        "\n",
        "file_list = np.sort(glob.glob(os.getcwd() + '/eval/npz/*.npz', recursive=True)).tolist()\n",
        "save_dir = os.getcwd() + '/eval/txt/reference/'\n",
        "\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "\n",
        "for file_idx in range(len(file_list)):\n",
        "\n",
        "    name = file_list[file_idx].split('/')[-1].split('.')[0]\n",
        "    print(\"\\r \" + str(file_idx+1) + \"/\" + str(len(file_list)) + \" \" + name, end = \"\")\n",
        "    with open(file_list[file_idx], 'rb') as f: \n",
        "        data = pickle.load(f)\n",
        "\n",
        "    b, d = data[1], data[2]\n",
        "    b, d = np.squeeze(b), np.squeeze(d)\n",
        "\n",
        "    if b.shape[0] > 1 and len(b.shape) > 1:\n",
        "      b_dechunked = b[0,:]\n",
        "      for chunk_idx in np.arange(1, b.shape[0]):\n",
        "        b_dechunked = np.append(b_dechunked, b[chunk_idx,50:])\n",
        "      Yb = b_dechunked\n",
        "    else:\n",
        "      Yb = b\n",
        "    if d.shape[0] > 1 and len(d.shape) > 1:\n",
        "      d_dechunked = d[0,:]\n",
        "      for chunk_idx in np.arange(1, d.shape[0]):\n",
        "        d_dechunked = np.append(d_dechunked, d[chunk_idx,50:])\n",
        "      Yd = d_dechunked\n",
        "    else:\n",
        "      Yd = d\n",
        "\n",
        "    Yb = np.argwhere(Yb == 1).flatten().astype(float)/100.0\n",
        "    Yd = np.argwhere(Yd == 1).flatten().astype(float)/100.0\n",
        "    \n",
        "    with open(save_dir + name + '_beat.txt', 'w') as f:\n",
        "      f.writelines('\\n'.join(Yb.astype(np.str)))\n",
        "    with open(save_dir + name + '_downbeat.txt', 'w') as f:\n",
        "      f.writelines('\\n'.join(Yd.astype(np.str)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 223/223 9_soul-groove9_105_beat_4-4"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jga40y-OA9JI"
      },
      "source": [
        "### BLSTM output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrUAFtp_EkfY"
      },
      "source": [
        "First we download & unzip the model to be used from GitHub"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BT1CLrcJI8Nf",
        "outputId": "ea013b45-f91d-4d28-c6df-bbd4cb7d1971"
      },
      "source": [
        "#@markdown ### Loading pre-trained model\n",
        "#@markdown If the training was skipped, we load the model from GitHub\n",
        "import os\n",
        "!wget https://github.com/marinaniet0/groove_beat_tracking/blob/main/models/blstm_49.pkl?raw=true -O blstm.pkl\n",
        "blstm_pkl = os.getcwd() + '/blstm.pkl'"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-28 22:05:33--  https://github.com/marinaniet0/groove_beat_tracking/blob/main/models/blstm_49.pkl?raw=true\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/marinaniet0/groove_beat_tracking/raw/main/models/blstm_49.pkl [following]\n",
            "--2021-05-28 22:05:34--  https://github.com/marinaniet0/groove_beat_tracking/raw/main/models/blstm_49.pkl\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/marinaniet0/groove_beat_tracking/main/models/blstm_49.pkl [following]\n",
            "--2021-05-28 22:05:34--  https://raw.githubusercontent.com/marinaniet0/groove_beat_tracking/main/models/blstm_49.pkl\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 327419 (320K) [application/octet-stream]\n",
            "Saving to: ‘blstm.pkl’\n",
            "\n",
            "blstm.pkl           100%[===================>] 319.75K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2021-05-28 22:05:34 (9.29 MB/s) - ‘blstm.pkl’ saved [327419/327419]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSzo2ttgEq5R"
      },
      "source": [
        "Then we run the validation files through the model to get the predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lB1bwlf9E5X4"
      },
      "source": [
        "import os\n",
        "import glob \n",
        "import numpy as np\n",
        "import pickle\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as func\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "torch.manual_seed(1)\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "sz = 50\n",
        "seq_len, batch_sz = sz * 2, 8\n",
        "input_dim, hidden_dim, beat_dim, downbeat_dim = 46, 25, seq_len * 2, seq_len * 2\n",
        "model_path = os.getcwd() + '/blstm.pkl'\n",
        "npz_path = os.getcwd() + '/eval/npz/'\n",
        "output_path = os.getcwd() + '/eval/txt/blstm/tmp/'"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GR2Gj2vPVVNq",
        "outputId": "936cac21-ff8f-4d1b-a4a3-018dbab38135"
      },
      "source": [
        "class custom_dataset(Dataset):\n",
        "    def __init__(self, x, yb, yd):\n",
        "        self.x = x \n",
        "        self.yb, self.yd = yb, yd\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.FloatTensor(self.x[idx]), torch.FloatTensor(self.yb[idx]), torch.FloatTensor(self.yd[idx])\n",
        "\n",
        "class Model(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_dim, hidden_dim, beat_dim, downbeat_dim):\n",
        "        super(Model, self).__init__()\n",
        "\n",
        "        # setting \n",
        "        self.flag = True\n",
        "        self.layer_sz = 2\n",
        "        self.bi_num = 2\n",
        "        self.norm = nn.LayerNorm([seq_len, input_dim])\n",
        "        self.rnn = nn.LSTM(input_dim, hidden_dim, batch_first=True, bidirectional=self.flag, num_layers=self.layer_sz)  \n",
        "\n",
        "        # initialization \n",
        "        for name, param in self.rnn.named_parameters():                   \n",
        "            if 'bias' in name:\n",
        "                nn.init.uniform_(param, a=-0.1, b=0.1)\n",
        "            elif 'weight' in name:\n",
        "                nn.init.uniform_(param, a=-0.1, b=0.1)\n",
        "\n",
        "        self.beat = nn.ModuleList([nn.Linear(hidden_dim * self.bi_num, 1), \\\n",
        "                                   nn.Linear(hidden_dim * self.bi_num, 1)])         \n",
        "        self.act = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):      \n",
        "\n",
        "        x = self.norm(x)\n",
        "        out, (hn, cn) = self.rnn(x)\n",
        "        b, d = self.beat[0](out), self.beat[1](out)                 \n",
        "        b, d = self.act(b), self.act(d)\n",
        "        b, d = b.squeeze(-1), d.squeeze(-1)               \n",
        "\n",
        "        return b, d \n",
        "\n",
        "def main():\n",
        "\n",
        "    print('Calculate tracking results of BLSTM.')\n",
        "    \n",
        "    file_list = np.sort(glob.glob(npz_path + '*.npz', recursive=True)).tolist() \n",
        "    model = Model(input_dim, hidden_dim, beat_dim, downbeat_dim)\n",
        "    model = model.to(device)\n",
        "    checkpoint = torch.load(model_path)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "    s = output_path\n",
        "    \n",
        "    for file_idx in range(len(file_list)):\n",
        "\n",
        "        # create a folder to store frames\n",
        "        name = file_list[file_idx].split('/')[-1].split('.')[0]\n",
        "        directory = s + str(name)\n",
        "        if not os.path.exists(directory):\n",
        "            os.makedirs(directory)     \n",
        "\n",
        "        # prepare dataset and loader \n",
        "        with open(file_list[file_idx], 'rb') as f:                      \n",
        "            data = pickle.load(f)\n",
        "        X_data, Yb_data, Yd_data = data[0], data[1], data[2]\n",
        "        dataset = custom_dataset(X_data, Yb_data, Yd_data)\n",
        "        loader = DataLoader(dataset, batch_size=batch_sz, drop_last=False)\n",
        "\n",
        "        model.eval()  \n",
        "        for idx, (x, yb, yd) in enumerate(loader):\n",
        "            x, yb, yd = x.to(device), yb.to(device), yd.to(device)\n",
        "            b, d = model.forward(x)\n",
        "            b, d = b.cpu().detach().numpy(), d.cpu().detach().numpy()\n",
        "\n",
        "            with open(s + str(name) + '/' + str(idx) + '_unit.npz', 'wb') as fp:\n",
        "                pickle.dump([b, d], fp)\n",
        "\n",
        "        # output \n",
        "        tmp_list = np.sort(glob.glob(s + str(name) + '/*.npz', recursive=True)).tolist() \n",
        "        b_arr, d_arr = [], []\n",
        "        for idx in range(len(tmp_list)):\n",
        "            with open(tmp_list[idx], 'rb') as f:\n",
        "                data = pickle.load(f)\n",
        "            b_arr.append(data[0])\n",
        "            d_arr.append(data[1])\n",
        "\n",
        "        beat, downbeat = np.concatenate(b_arr), np.concatenate(d_arr)\n",
        "        beat, downbeat = beat.reshape(-1, 1), downbeat.reshape(-1, 1)\n",
        "\n",
        "        with open(s + str(name) + '.npz', 'wb') as f:\n",
        "            pickle.dump([beat, downbeat], f) \n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculate tracking results of BLSTM.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WJod1GyVw4E"
      },
      "source": [
        "We apply thresholds to the outputs: 0.3 to the beats and 0.2 to the downbeats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoUBWpZAVYcI"
      },
      "source": [
        "import os\n",
        "import glob \n",
        "import numpy as np\n",
        "import pickle \n",
        "\n",
        "pred_path = os.getcwd() + \"/eval/txt/blstm/pred/\"\n",
        "if not os.path.exists(pred_path):\n",
        "  os.makedirs(pred_path)\n",
        "\n",
        "# Threshold -> probabilities to beat or no beat, downbeat or no downbeat\n",
        "beat_thres, db_thres = 0.3, 0.2\n",
        "file_list = np.sort(glob.glob(output_path + '/*.npz', recursive=True)).tolist() \n",
        "\n",
        "for file_idx in range(len(file_list)):\n",
        "\n",
        "    name = file_list[file_idx].split('/')[-1].split('.')[0]\n",
        "\n",
        "    with open(file_list[file_idx], 'rb') as f: \n",
        "        data = pickle.load(f)\n",
        "\n",
        "    b, d = data[0], data[1]\n",
        "    b, d = np.squeeze(b), np.squeeze(d)\n",
        "    b, d = b.tolist(), d.tolist()\n",
        "\n",
        "    b_out, d_out = [], []\n",
        "    for i in range(len(b)):\n",
        "        if b[i] >= beat_thres:\n",
        "            b_out.append(str(np.round(float(i) * 0.01, 2)) + '\\n')\n",
        "        if d[i] >= db_thres:\n",
        "            d_out.append(str(np.round(float(i) * 0.01, 2)) + '\\n')\n",
        "\n",
        "    s = pred_path + str(name) + '_beat.txt'\n",
        "    if os.path.exists(s):\n",
        "        os.system(\"rm \" + s)\n",
        "    with open(pred_path + str(name) + '_beat.txt', 'a') as fp:\n",
        "        fp.writelines(b_out)\n",
        "\n",
        "    s = pred_path + str(name) + '_downbeat.txt'\n",
        "    if os.path.exists(s):\n",
        "        os.system(\"rm \" + s)\n",
        "    with open(pred_path + str(name) + '_downbeat.txt', 'a') as fp:\n",
        "        fp.writelines(d_out)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnQrT70tI-Fn"
      },
      "source": [
        "### BLSTM + Attention output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIejUQqRFJgC"
      },
      "source": [
        "First we download & unzip the model to be used from GitHub"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p78GuyZtFKDl",
        "outputId": "9e826164-975b-427d-97db-c95fb2c37c1d"
      },
      "source": [
        "#@markdown ### Loading pre-trained model\n",
        "#@markdown If the training was skipped, we load the model from GitHub\n",
        "import os\n",
        "!wget https://github.com/marinaniet0/groove_beat_tracking/blob/main/models/attn_49.pkl?raw=true -O blstm-attn.pkl\n",
        "blstm_pkl = os.getcwd() + '/blstm-attn.pkl'"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-28 22:07:03--  https://github.com/marinaniet0/groove_beat_tracking/blob/main/models/attn_49.pkl?raw=true\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/marinaniet0/groove_beat_tracking/raw/main/models/attn_49.pkl [following]\n",
            "--2021-05-28 22:07:03--  https://github.com/marinaniet0/groove_beat_tracking/raw/main/models/attn_49.pkl\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/marinaniet0/groove_beat_tracking/main/models/attn_49.pkl [following]\n",
            "--2021-05-28 22:07:03--  https://raw.githubusercontent.com/marinaniet0/groove_beat_tracking/main/models/attn_49.pkl\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 343263 (335K) [application/octet-stream]\n",
            "Saving to: ‘blstm-attn.pkl’\n",
            "\n",
            "blstm-attn.pkl      100%[===================>] 335.22K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2021-05-28 22:07:03 (9.65 MB/s) - ‘blstm-attn.pkl’ saved [343263/343263]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_2RWyq3FKqo"
      },
      "source": [
        "Then we run the validation files through the model to get the predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tb9wORZ1JDLB"
      },
      "source": [
        "import os\n",
        "import glob \n",
        "import numpy as np\n",
        "import pickle\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as func\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "torch.manual_seed(1)\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "sz = 50\n",
        "seq_len, batch_sz = sz * 2, 8\n",
        "input_dim, hidden_dim, beat_dim, downbeat_dim = 46, 25, seq_len * 2, seq_len * 2\n",
        "model_path = os.getcwd() + '/blstm-attn.pkl'\n",
        "npz_path = os.getcwd() + '/eval/npz/'\n",
        "output_path = os.getcwd() + '/eval/txt/attn/tmp/'"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIeOHntoJAoN",
        "outputId": "b71c97c6-9711-427d-e381-ff1d2d0bf676"
      },
      "source": [
        "class custom_dataset(Dataset):\n",
        "    def __init__(self, x, yb, yd):\n",
        "        self.x = x \n",
        "        self.yb, self.yd = yb, yd\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.FloatTensor(self.x[idx]), torch.FloatTensor(self.yb[idx]), torch.FloatTensor(self.yd[idx])\n",
        "\n",
        "class Attention(nn.Module):\n",
        "\n",
        "    def __init__(self, dimensions, attention_type='general'):\n",
        "        super(Attention, self).__init__()\n",
        "\n",
        "        if attention_type not in ['dot', 'general']:\n",
        "            raise ValueError('Invalid attention type selected.')\n",
        "\n",
        "        self.attention_type = attention_type\n",
        "        if self.attention_type == 'general':\n",
        "            self.linear_in = nn.Linear(dimensions, dimensions, bias=False)\n",
        "\n",
        "        self.linear_out = nn.Linear(dimensions * 2, dimensions, bias=False)\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, query, context):\n",
        "\n",
        "        batch_size, output_len, dimensions = query.size()\n",
        "        query_len = context.size(1)\n",
        "\n",
        "        if self.attention_type == \"general\":\n",
        "            query = query.reshape(batch_size * output_len, dimensions)\n",
        "            query = self.linear_in(query)\n",
        "            query = query.reshape(batch_size, output_len, dimensions)\n",
        "\n",
        "        attention_scores = torch.bmm(query, context.transpose(1, 2).contiguous())\n",
        "        attention_scores = attention_scores.view(batch_size * output_len, query_len)\n",
        "\n",
        "        attention_weights = self.softmax(attention_scores)\n",
        "        attention_weights = attention_weights.view(batch_size, output_len, query_len)\n",
        "\n",
        "        mix = torch.bmm(attention_weights, context)\n",
        "\n",
        "        combined = torch.cat((mix, query), dim=2)\n",
        "        combined = combined.view(batch_size * output_len, 2 * dimensions)\n",
        "\n",
        "        output = self.linear_out(combined).view(batch_size, output_len, dimensions)\n",
        "        output = self.tanh(output)\n",
        "\n",
        "        return output, attention_weights\n",
        "\n",
        "class Model(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_dim, hidden_dim, beat_dim, downbeat_dim):\n",
        "        super(Model, self).__init__()\n",
        "\n",
        "        # setting \n",
        "        self.flag = True\n",
        "        self.layer_sz = 2\n",
        "\n",
        "        # layer \n",
        "        self.norm = nn.LayerNorm([seq_len, input_dim])\n",
        "        self.rnn = nn.LSTM(input_dim, hidden_dim, batch_first=True, bidirectional=self.flag, num_layers=self.layer_sz)  \n",
        "        for name, param in self.rnn.named_parameters():                   # initialization\n",
        "            if 'bias' in name:\n",
        "                nn.init.uniform_(param, a=-0.1, b=0.1)\n",
        "            elif 'weight' in name:\n",
        "                nn.init.uniform_(param, a=-0.1, b=0.1)\n",
        "\n",
        "        self.beat = nn.ModuleList([nn.Linear(hidden_dim, 1), \\\n",
        "                                   nn.Linear(hidden_dim, 1)])       \n",
        "\n",
        "        self.attn = Attention(hidden_dim)\n",
        "        self.act = nn.Sigmoid()\n",
        "    \n",
        "    def forward(self, raw):     \n",
        "\n",
        "        x = self.norm(raw)\n",
        "        out, (hn, cn) = self.rnn(x) \n",
        "        out_tmp = torch.chunk(out, 2, -1)\n",
        "        out_tmp = out_tmp[0] + out_tmp[1] \n",
        "        hn = hn.permute(1, 0, 2)\n",
        "        attn_out, weights = self.attn(out_tmp, hn)    \n",
        "\n",
        "        # beat \n",
        "        b, d = self.beat[0](attn_out), self.beat[1](attn_out) \n",
        "        b, d = self.act(b), self.act(d)\n",
        "        b, d = b.squeeze(-1), d.squeeze(-1)                   \n",
        "\n",
        "        return b, d, out, attn_out   \n",
        "\n",
        "def main():\n",
        "\n",
        "    print('Calculate tracking results of BLSTM-Attn.')\n",
        "\n",
        "    file_list = np.sort(glob.glob(npz_path + '*.npz', recursive=True)).tolist() \n",
        "    model = Model(input_dim, hidden_dim, beat_dim, downbeat_dim)\n",
        "    model = model.to(device)\n",
        "    checkpoint = torch.load(model_path)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "    s = output_path\n",
        "    if not os.path.exists(s):\n",
        "      os.makedirs(s)\n",
        "    \n",
        "    for file_idx in range(len(file_list)):\n",
        "\n",
        "        print('\\r' + file_list[file_idx], end=\"\")\n",
        "        # create a folder to store frames\n",
        "        name = file_list[file_idx].split('/')[-1].split('.')[0]\n",
        "        directory = s + str(name)\n",
        "        if not os.path.exists(directory):\n",
        "            os.makedirs(directory)     \n",
        "\n",
        "        # prepare dataset and loader \n",
        "        with open(file_list[file_idx], 'rb') as f:                      \n",
        "            data = pickle.load(f)\n",
        "        X_data, Yb_data, Yd_data = data[0], data[1], data[2]\n",
        "        dataset = custom_dataset(X_data, Yb_data, Yd_data)\n",
        "        loader = DataLoader(dataset, batch_size=batch_sz, drop_last=False)\n",
        "\n",
        "        model.eval()  \n",
        "        for idx, (x, yb, yd) in enumerate(loader):\n",
        "\n",
        "            x, yb, yd = x.to(device), yb.to(device), yd.to(device)\n",
        "            b, d, _, _ = model.forward(x)\n",
        "            b, d = b.cpu().detach().numpy(), d.cpu().detach().numpy()\n",
        "\n",
        "            with open(s + str(name) + '/' + str(idx) + '_unit.npz', 'wb') as fp:\n",
        "                pickle.dump([b, d], fp)\n",
        "\n",
        "        # output \n",
        "        tmp_list = np.sort(glob.glob(s + str(name) + '/*.npz', recursive=True)).tolist() \n",
        "        b_arr, d_arr = [], []\n",
        "        for idx in range(len(tmp_list)):\n",
        "            with open(tmp_list[idx], 'rb') as f:\n",
        "                data = pickle.load(f)\n",
        "            b_arr.append(data[0])\n",
        "            d_arr.append(data[1])\n",
        "\n",
        "        beat, downbeat = np.concatenate(b_arr), np.concatenate(d_arr)\n",
        "        beat, downbeat = beat.reshape(-1, 1), downbeat.reshape(-1, 1)\n",
        "\n",
        "        with open(s + str(name) + '.npz', 'wb') as f:\n",
        "            pickle.dump([beat, downbeat], f) \n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculate tracking results of BLSTM-Attn.\n",
            "/content/eval/npz/9_soul-groove9_105_beat_4-4.npz"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBytDXfSVuf7"
      },
      "source": [
        "We apply thresholds to the outputs: 0.3 to the beats and 0.2 to the downbeats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Zp5jRuBV0Fz"
      },
      "source": [
        "import os\n",
        "import glob \n",
        "import numpy as np\n",
        "import pickle \n",
        "\n",
        "pred_path = os.getcwd() + \"/eval/txt/attn/pred/\"\n",
        "if not os.path.exists(pred_path):\n",
        "  os.makedirs(pred_path)\n",
        "\n",
        "beat_thres, db_thres = 0.3, 0.2\n",
        "file_list = np.sort(glob.glob(output_path + '/*.npz', recursive=True)).tolist() \n",
        "\n",
        "for file_idx in range(len(file_list)):\n",
        "\n",
        "    name = file_list[file_idx].split('/')[-1].split('.')[0]\n",
        "\n",
        "    with open(file_list[file_idx], 'rb') as f: \n",
        "        data = pickle.load(f)\n",
        "\n",
        "    b, d = data[0], data[1]\n",
        "    b, d = np.squeeze(b), np.squeeze(d)\n",
        "    b, d = b.tolist(), d.tolist()\n",
        "\n",
        "    b_out, d_out = [], []\n",
        "    for i in range(len(b)):\n",
        "        if b[i] >= beat_thres:\n",
        "            b_out.append(str(np.round(float(i) * 0.01, 2)) + '\\n')\n",
        "        if d[i] >= db_thres:\n",
        "            d_out.append(str(np.round(float(i) * 0.01, 2)) + '\\n')\n",
        "\n",
        "    s = pred_path + str(name) + '_beat.txt'\n",
        "    if os.path.exists(s):\n",
        "        os.system(\"rm \" + s)\n",
        "    with open(pred_path + str(name) + '_beat.txt', 'a') as fp:\n",
        "        fp.writelines(b_out)\n",
        "\n",
        "    s = pred_path + str(name) + '_downbeat.txt'\n",
        "    if os.path.exists(s):\n",
        "        os.system(\"rm \" + s)\n",
        "    with open(pred_path + str(name) + '_downbeat.txt', 'a') as fp:\n",
        "        fp.writelines(d_out)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCZRlrcpETo6"
      },
      "source": [
        "### Getting scores with mir_eval"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeUK64HIV3dv",
        "outputId": "18b8609c-ae94-4a18-ec50-7d97d964bd4e"
      },
      "source": [
        "!pip install mir_eval"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mir_eval\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/fe/be4f7a59ed71938e21e89f23afe93eea0d39eb3e77f83754a12028cf1a68/mir_eval-0.6.tar.gz (87kB)\n",
            "\r\u001b[K     |███▊                            | 10kB 11.4MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 20kB 14.9MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 30kB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 40kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 51kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 61kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 71kB 6.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 81kB 6.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 92kB 4.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from mir_eval) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from mir_eval) (1.4.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from mir_eval) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from mir_eval) (1.15.0)\n",
            "Building wheels for collected packages: mir-eval\n",
            "  Building wheel for mir-eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mir-eval: filename=mir_eval-0.6-cp37-none-any.whl size=96515 sha256=2fabfa78cfff35af39cce52042bcc2f3087434d895b45e4ea782659c28ca3c1b\n",
            "  Stored in directory: /root/.cache/pip/wheels/49/ce/30/730fa72addf275e49d90683b01b3613048b4be3bf7ff8eb6ec\n",
            "Successfully built mir-eval\n",
            "Installing collected packages: mir-eval\n",
            "Successfully installed mir-eval-0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sSkcsyRV4K_"
      },
      "source": [
        "ref_beat_dir = os.getcwd() + '/eval/txt/reference/'\n",
        "attn_beat_dir = os.getcwd() + '/eval/txt/attn/pred/'\n",
        "blstm_beat_dir = os.getcwd() + '/eval/txt/blstm/pred/'\n",
        "\n",
        "beat_end = '_beat.txt'\n",
        "downbeat_end = '_downbeat.txt'\n",
        "\n",
        "file_list = []\n",
        "\n",
        "for root, dirs, files in os.walk(ref_beat_dir):\n",
        "  for f in files:\n",
        "    file_list.append(f)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X14LaUDjV6GQ",
        "outputId": "d90c82b9-3c78-4555-e7ee-c69f6cf4db5c"
      },
      "source": [
        "import mir_eval\n",
        "\n",
        "n_files = len(file_list)\n",
        "scores_beats_blstm = []\n",
        "scores_downbeats_blstm = []\n",
        "scores_beats_attn = []\n",
        "scores_downbeats_attn = []\n",
        "\n",
        "print(n_files)\n",
        "for file in file_list:\n",
        "  print('\\r' + file, end=\"\")\n",
        "  if file.endswith(beat_end):\n",
        "    ref_beats = mir_eval.io.load_events(ref_beat_dir + file)\n",
        "    attn_pred_beats = mir_eval.io.load_events(attn_beat_dir + file)\n",
        "    blstm_pred_beats = mir_eval.io.load_events(blstm_beat_dir + file)\n",
        "    \n",
        "    scores_beats_attn.append(mir_eval.beat.evaluate(ref_beats, attn_pred_beats))\n",
        "    scores_beats_blstm.append(mir_eval.beat.evaluate(ref_beats, blstm_pred_beats))\n",
        "\n",
        "  elif file.endswith(downbeat_end):\n",
        "    ref_downbeats = mir_eval.io.load_events(ref_beat_dir + file)\n",
        "    attn_pred_downbeats = mir_eval.io.load_events(attn_beat_dir + file)\n",
        "    blstm_pred_downbeats = mir_eval.io.load_events(blstm_beat_dir + file)\n",
        "    \n",
        "    scores_downbeats_attn.append(mir_eval.beat.evaluate(ref_beats, attn_pred_beats))\n",
        "    scores_downbeats_blstm.append(mir_eval.beat.evaluate(ref_beats, blstm_pred_beats))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "446\n",
            "\r11_rock_100_beat_4-4_beat.txt\r109_rock_95_beat_4-4_beat.txt\r33_hiphop_100_fill_4-4_downbeat.txt\r88_neworleans-funk_93_fill_4-4_beat.txt\r167_afrocuban-rhumba_110_fill_4-4_downbeat.txt\r257_funk-purdieshuffle_130_fill_4-4_beat.txt\r54_jazz_125_fill_4-4_downbeat.txt\r205_rock-halftime_140_fill_4-4_downbeat.txt\r24_rock_90_beat_4-4_beat.txt"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/mir_eval/beat.py:91: UserWarning: Reference beats are empty.\n",
            "  warnings.warn(\"Reference beats are empty.\")\n",
            "/usr/local/lib/python3.7/dist-packages/mir_eval/beat.py:93: UserWarning: Estimated beats are empty.\n",
            "  warnings.warn(\"Estimated beats are empty.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "218_rock-halftime_140_fill_4-4_downbeat.txt"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/mir_eval/beat.py:376: UserWarning: Only one estimated beat was provided, so beat intervals cannot be computed.\n",
            "  warnings.warn(\"Only one estimated beat was provided, so beat intervals\"\n",
            "/usr/local/lib/python3.7/dist-packages/mir_eval/beat.py:464: UserWarning: Only one estimated beat was provided, so beat intervals cannot be computed.\n",
            "  warnings.warn(\"Only one estimated beat was provided, so beat intervals\"\n",
            "/usr/local/lib/python3.7/dist-packages/mir_eval/beat.py:622: UserWarning: Only one estimated beat was provided, so beat intervals cannot be computed.\n",
            "  warnings.warn(\"Only one estimated beat was provided, so beat intervals\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "7_latin-brazilian-maracatu_96_beat_4-4_beat.txt"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "26_rock_120_beat_4-4_downbeat.txt"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeiaYjRFV75D",
        "outputId": "7dcd6a4d-5d86-4b5a-a66c-654af51b8dfb"
      },
      "source": [
        "beat_blstm_pscore=0\n",
        "beat_blstm_fmeasure=0\n",
        "downbeat_blstm_pscore=0\n",
        "downbeat_blstm_fmeasure=0\n",
        "for score in scores_beats_blstm:\n",
        "  beat_blstm_fmeasure+=score[\"F-measure\"]\n",
        "  beat_blstm_pscore+=score[\"P-score\"]\n",
        "for score in scores_downbeats_blstm:\n",
        "  downbeat_blstm_fmeasure+=score[\"F-measure\"]\n",
        "  downbeat_blstm_pscore+=score[\"P-score\"]\n",
        "\n",
        "beat_blstm_pscore=beat_blstm_pscore/len(scores_beats_blstm)\n",
        "beat_blstm_fmeasure=beat_blstm_fmeasure/len(scores_beats_blstm)\n",
        "downbeat_blstm_pscore=downbeat_blstm_pscore/len(scores_beats_blstm)\n",
        "downbeat_blstm_fmeasure=downbeat_blstm_fmeasure/len(scores_beats_blstm)\n",
        "\n",
        "\n",
        "beat_attn_pscore=0\n",
        "beat_attn_fmeasure=0\n",
        "downbeat_attn_pscore=0\n",
        "downbeat_attn_fmeasure=0\n",
        "for score in scores_beats_attn:\n",
        "  beat_attn_fmeasure+=score[\"F-measure\"]\n",
        "  beat_attn_pscore+=score[\"P-score\"]\n",
        "for score in scores_downbeats_attn:\n",
        "  downbeat_attn_fmeasure+=score[\"F-measure\"]\n",
        "  downbeat_attn_pscore+=score[\"P-score\"]\n",
        "\n",
        "beat_attn_pscore=beat_attn_pscore/len(scores_beats_attn)\n",
        "beat_attn_fmeasure=beat_attn_fmeasure/len(scores_beats_attn)\n",
        "downbeat_attn_pscore=downbeat_attn_pscore/len(scores_beats_attn)\n",
        "downbeat_attn_fmeasure=downbeat_attn_fmeasure/len(scores_beats_attn)\n",
        "\n",
        "print(\"BLSTM -------------------------\")\n",
        "print(\"P-score beats: \" + str(beat_blstm_pscore))\n",
        "print(\"F-measure beats: \" + str(beat_blstm_fmeasure))\n",
        "print(\"P-score downbeats: \" + str(downbeat_blstm_pscore))\n",
        "print(\"F-measure downbeats: \" + str(downbeat_blstm_fmeasure))\n",
        "\n",
        "print(\"BLSTM+Attn ---------------------\")\n",
        "print(\"P-score beats: \" + str(beat_attn_pscore))\n",
        "print(\"F-measure beats: \" + str(beat_attn_fmeasure))\n",
        "print(\"P-score downbeats: \" + str(downbeat_attn_pscore))\n",
        "print(\"F-measure downbeats: \" + str(downbeat_attn_fmeasure))\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BLSTM -------------------------\n",
            "P-score beats: 0.05231426141500952\n",
            "F-measure beats: 0.04412704099978594\n",
            "P-score downbeats: 0.04108000833190337\n",
            "F-measure downbeats: 0.031770015576410265\n",
            "BLSTM+Attn ---------------------\n",
            "P-score beats: 0.05247023405771346\n",
            "F-measure beats: 0.04348409893576909\n",
            "P-score downbeats: 0.0405724957697746\n",
            "F-measure downbeats: 0.031342496367446654\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}